{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento con retropropagación\n",
    "\n",
    "En este ejercicio implementaremos el algoritmo de retropropagación dentro del descenso por gradiente para actualizar todos los pesos de la red durante varias épocas. Para entrenar la red usaremos el conjunto de datos de calificaciones que vimos previamente.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importamos paquetes y datos\n",
    "import numpy as np\n",
    "from data_prep import features, targets, features_test, targets_test\n",
    "\n",
    "# Definiciones útiles\n",
    "np.random.seed(21)\n",
    "\n",
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    Calculate sigmoid\n",
    "    \"\"\"\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_prime(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparámetros\n",
    "n_hidden = 2  # number of hidden units\n",
    "epochs = 900\n",
    "learnrate = 0.005\n",
    "\n",
    "# Obtenemos el número de entradas (features) asi como el número de ejemplos (n_records)\n",
    "n_records, n_features = features.shape\n",
    "last_loss = None\n",
    "\n",
    "# Creamos las matrices de los pesos.\n",
    "weights_input_hidden = np.random.normal(scale=1 / n_features ** .5,\n",
    "                                        size=(n_features, n_hidden))\n",
    "\n",
    "weights_hidden_output = np.random.normal(scale=1 / n_features ** .5,\n",
    "                                         size=n_hidden)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss:  0.276316003608671\n",
      "Train loss:  0.27630890702514715\n",
      "Train loss:  0.276301811406519\n",
      "Train loss:  0.27629471675263506\n",
      "Train loss:  0.2762876230633442\n",
      "Train loss:  0.276280530338495\n",
      "Train loss:  0.2762734385779361\n",
      "Train loss:  0.2762663477815164\n",
      "Train loss:  0.27625925794908457\n",
      "Train loss:  0.2762521690804895\n",
      "Prediction accuracy: 0.300\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for e in range(epochs):\n",
    "    del_w_input_hidden = np.zeros(weights_input_hidden.shape)\n",
    "    del_w_hidden_output = np.zeros(weights_hidden_output.shape)\n",
    "    for x, y in zip(features.values, targets):\n",
    "        ## Forward pass ##\n",
    "        # TODO: Calculate the output\n",
    "        hidden_input = np.dot(x, weights_input_hidden)\n",
    "        hidden_output = sigmoid(hidden_input)\n",
    "        output = sigmoid(np.dot(hidden_output, weights_hidden_output))\n",
    "\n",
    "        ## Backward pass ##\n",
    "        # TODO: Calculate the error\n",
    "        error = y - output\n",
    "\n",
    "        # TODO: Calculate error gradient in output unit\n",
    "        output_error = error * sigmoid_prime(output)\n",
    "\n",
    "        # TODO: propagate errors to hidden layer\n",
    "        hidden_error = error * sigmoid_prime(output) * weights_hidden_output\n",
    "\n",
    "        # TODO: Update the change in weights\n",
    "        del_w_hidden_output += learnrate * output_error * hidden_output\n",
    "        del_w_input_hidden += learnrate * hidden_error * x[:,None]\n",
    "\n",
    "    # TODO: Update weights\n",
    "    weights_input_hidden += (1 / n_records) * del_w_input_hidden\n",
    "    weights_hidden_output += (1 / n_records) * del_w_hidden_output\n",
    "\n",
    "    # Printing out the mean square error on the training set\n",
    "    if e % (epochs / 10) == 0:\n",
    "        hidden_output = sigmoid(np.dot(x, weights_input_hidden))\n",
    "        out = sigmoid(np.dot(hidden_output,\n",
    "                             weights_hidden_output))\n",
    "        loss = np.mean((out - targets) ** 2)\n",
    "\n",
    "        if last_loss and last_loss < loss:\n",
    "            print(\"Train loss: \", loss, \"  WARNING - Loss Increasing\")\n",
    "        else:\n",
    "            print(\"Train loss: \", loss)\n",
    "        last_loss = loss\n",
    "\n",
    "# Calculate accuracy on test data\n",
    "hidden = sigmoid(np.dot(features_test, weights_input_hidden))\n",
    "out = sigmoid(np.dot(hidden, weights_hidden_output))\n",
    "predictions = out > 0.5\n",
    "accuracy = np.mean(predictions == targets_test)\n",
    "print(\"Prediction accuracy: {:.3f}\".format(accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nni",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cbad788490f55b163920bee5e9d5e0cba00db5905dc94f4bdbe0011e55bf465f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
